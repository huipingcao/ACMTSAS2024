{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load necessary libs .....\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, BCELoss, BCEWithLogitsLoss\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "from model import GraphEncoder\n",
    "from readData import LoadData, LoadGraph\n",
    "import os\n",
    "from MultiCostNetworks import MultiCostNetworks\n",
    "import sys\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "print(\"Load necessary libs .....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# gDB = \"C9_NY_1K\"\n",
    "# path = \"/home/gqxwolf/shared_git/BackboneIndex/Data/\"+gDB+\"/\"\n",
    "# path\n",
    "path = '/Users/hyingchen/PycharmProjects/ICDE23/GNNquery/Graph_data/datasets/sample_graph/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(5000, Data(x=[5000, 2], edge_index=[2, 14194], edge_attr=[14194, 3]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = LoadGraph(path)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Process (5000, Data(x=[5000, 2], edge_index=[2, 14194], edge_attr=[14194, 3]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'SegInfo.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m train_paths_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Users/hyingchen/PycharmProjects/ICDE23/GNNquery/Graph_data/datasets/sample_graph/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     17\u001B[0m root \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Users/hyingchen/PycharmProjects/ICDE23/GNNquery/Graph_data/datasets/sample_graph\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 19\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mMultiCostNetworks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_paths_folder\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_paths_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m MultiCostNetworks(graph, train_paths_folder \u001B[38;5;241m=\u001B[39m train_paths_folder, root\u001B[38;5;241m=\u001B[39mroot,split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/ICDE23/GNNquery/SkylineGNN_py/003/MultiCostNetworks.py:43\u001B[0m, in \u001B[0;36mMultiCostNetworks.__init__\u001B[0;34m(self, dataset, train_paths_folder, root, ratio, split, transform, pre_transform)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m dataset\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_paths_folder \u001B[38;5;241m=\u001B[39m train_paths_folder\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mMultiCostNetworks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_transform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m index \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mindex(split)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mslices \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_paths[index])\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/GNNquery/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:56\u001B[0m, in \u001B[0;36mInMemoryDataset.__init__\u001B[0;34m(self, root, transform, pre_transform, pre_filter)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, root: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     53\u001B[0m              transform: Optional[Callable] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     54\u001B[0m              pre_transform: Optional[Callable] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     55\u001B[0m              pre_filter: Optional[Callable] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 56\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_transform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_filter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mslices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/GNNquery/lib/python3.9/site-packages/torch_geometric/data/dataset.py:87\u001B[0m, in \u001B[0;36mDataset.__init__\u001B[0;34m(self, root, transform, pre_transform, pre_filter)\u001B[0m\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_download()\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprocess\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[0;32m---> 87\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/GNNquery/lib/python3.9/site-packages/torch_geometric/data/dataset.py:170\u001B[0m, in \u001B[0;36mDataset._process\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProcessing...\u001B[39m\u001B[38;5;124m'\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mstderr)\n\u001B[1;32m    169\u001B[0m makedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_dir)\n\u001B[0;32m--> 170\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m path \u001B[38;5;241m=\u001B[39m osp\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpre_transform.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    173\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(_repr(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_transform), path)\n",
      "File \u001B[0;32m~/PycharmProjects/ICDE23/GNNquery/SkylineGNN_py/003/MultiCostNetworks.py:66\u001B[0m, in \u001B[0;36mMultiCostNetworks.process\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     63\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcess \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, f \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw_paths)):\n\u001B[0;32m---> 66\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[43mreadLogs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;66;03m# print(torch.zeros(self.data.num_nodes, 2).shape)\u001B[39;00m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# print(self.data.x.shape)\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;66;03m# new_x[p.src][2] = 1\u001B[39;00m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;66;03m# new_x[p.dest][2] = 1\u001B[39;00m\n\u001B[1;32m     76\u001B[0m     new_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mx\n",
      "File \u001B[0;32m~/PycharmProjects/ICDE23/GNNquery/SkylineGNN_py/003/readData.py:279\u001B[0m, in \u001B[0;36mreadLogs\u001B[0;34m(filename, t_i)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filename) \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[1;32m    278\u001B[0m     Lines \u001B[38;5;241m=\u001B[39m fp\u001B[38;5;241m.\u001B[39mreadlines()\n\u001B[0;32m--> 279\u001B[0m     src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbasename\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m     dest \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(basename(filename)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;66;03m# print(src, dest)\u001B[39;00m\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;66;03m# print(basename(filename))\u001B[39;00m\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;66;03m# sys.exit()\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: 'SegInfo.txt'"
     ]
    }
   ],
   "source": [
    "node_dim = 2\n",
    "edge_dim = 3\n",
    "embedding_dim = 512\n",
    "hidden_dim = 512\n",
    "batch_size = 64\n",
    "enable_embed = True\n",
    "output_dim =3\n",
    "model_name=\"SAGE\"\n",
    "n=1000\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "# train_paths_folder = \"/home/gqxwolf/shared_git/BackboneIndex/Data/results/\"+gDB+\"/training_GNN\"\n",
    "# root = \"/home/gqxwolf/mydata/GNN_Combinatroal/data/\"+gDB\n",
    "train_paths_folder = \"/Users/hyingchen/PycharmProjects/ICDE23/GNNquery/Graph_data/datasets/sample_graph/\"\n",
    "root = \"/Users/hyingchen/PycharmProjects/ICDE23/GNNquery/Graph_data/datasets/sample_graph\"\n",
    "\n",
    "train_dataset = MultiCostNetworks(graph, train_paths_folder = train_paths_folder, root=root, split='train')\n",
    "test_dataset = MultiCostNetworks(graph, train_paths_folder = train_paths_folder, root=root,split='test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch(batch=[64000], dest_node_idx=[64], edge_attr=[195712, 3], edge_index=[2, 195712], ptr=[65], src_node_idx=[64], x=[64000, 2], y=[64000])\ntensor([  225,  1845,  2590,  3530,  4975,  5146,  6053,  7129,  8327,  9160,\n        10867, 11829, 12671, 13519, 14945, 15337, 16097, 17321, 18187, 19608,\n        20817, 21499, 22051, 23226, 24888, 25613, 26682, 27973, 28224, 29374,\n        30960, 31815, 32083, 33482, 34721, 35812, 36008, 37558, 38533, 39709,\n        40747, 41374, 42492, 43534, 44006, 45750, 46155, 47232, 48875, 49347,\n        50084, 51961, 52012, 53234, 54339, 55742, 56907, 57740, 58090, 59566,\n        60885, 61782, 62271, 63589])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, drop_last=True, batch_size=batch_size)\n",
    "\n",
    "for data in train_loader:\n",
    "  print(data)\n",
    "  src_list = torch.tensor([data.src_node_idx[i].item() + i * n for i in range(len(data.src_node_idx))])\n",
    "  dest_list = torch.tensor([data.dest_node_idx[i].item() + i * n for i in range(len(data.dest_node_idx))])\n",
    "  print(src_list)\n",
    "  break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "64\n512\nFinish model initialization !!!!\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, drop_last=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, drop_last=True, batch_size=batch_size)\n",
    "\n",
    "model = GraphEncoder(node_dim, edge_dim, embedding_dim, hidden_dim, output_num_class=output_dim, device=device, enable_embedding=enable_embed,\n",
    "                     batch=batch_size, model_name = model_name).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "inital the train function\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_pre_n = 0\n",
    "    total_n = 0\n",
    "    total_graphs = 0\n",
    "\n",
    "    for index, data in enumerate(train_loader):\n",
    "        start_time = time.time()\n",
    "        data = data.to(device)\n",
    "        # print(data, data.src_node_idx, data.dest_node_idx)\n",
    "        logits = model(data)\n",
    "        # print(logits)\n",
    "        # print(data.y, (data.y.cpu().detach().numpy() == 1).sum())\n",
    "        loss = F.nll_loss(logits, data.y)\n",
    "\n",
    "        total_pre_n += (np.argmax(logits.cpu().detach().numpy(), axis=1) == 1).sum() + (\n",
    "                    np.argmax(logits.cpu().detach().numpy(), axis=1) == 2).sum()\n",
    "        total_n += ((data.y.cpu().detach().numpy() == 1).sum())\n",
    "\n",
    "        total_graphs += data.num_graphs\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "        optimizer.step()\n",
    "        # print(index, time.time()-start_time)\n",
    "\n",
    "    return total_loss / len(train_dataset), total_pre_n / total_graphs, total_n / total_graphs\n",
    "\n",
    "print(\"inital the train function\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial the test function\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_pre_n = 0\n",
    "    total_n = 0\n",
    "    total_graphs = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "\n",
    "        loss = F.nll_loss(logits, data.y)\n",
    "\n",
    "        total_pre_n += (np.argmax(logits.cpu().detach().numpy(), axis=1) == 1).sum() + (\n",
    "                np.argmax(logits.cpu().detach().numpy(), axis=1) == 2).sum()\n",
    "        total_n += ((data.y.cpu().detach().numpy() == 1).sum())\n",
    "\n",
    "        total_graphs += data.num_graphs\n",
    "\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "\n",
    "        # if n!=0:\n",
    "        #     print(count, np.argmax(logits.cpu().numpy(),axis=1), n )\n",
    "        #     sys.exit()\n",
    "\n",
    "    return total_loss / len(loader), total_pre_n / total_graphs, total_n / total_graphs\n",
    "print(\"initial the test function\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64000, 2])\n",
      "torch.Size([64000, 1536])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "0",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 0\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = test_auc = 0\n",
    "for epoch in range(0, 10000):\n",
    "    start_time = time.time()\n",
    "    loss, pre_n, n = train()\n",
    "    val_auc, test_p_n, test_n = test(test_loader)\n",
    "    end_time = time.time()\n",
    "    if epoch%10==0:\n",
    "      print(\"Epoch:{}, Loss:{:.4f}[{:.5f} - {:.5f}], Val:{:.4f}[{:.5f} - {:.5f}], running time each epoch:{:.2f}\".format(epoch, loss, pre_n, n, val_auc, test_p_n, test_n, (end_time - start_time)))\n",
    "    if epoch%200==0:\n",
    "      check_pt_path = \"/content/drive/MyDrive/ColabNotebooks/GNN_Skyline/models/{}/{}_{}_{}_{}_train_checkpoint_{}_2GNN3FF_10k_train_samples.pt\".format(gDB, embedding_dim, hidden_dim, batch_size, epoch,model_name)\n",
    "      torch.save({'epoch': epoch,'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': loss,}, check_pt_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "24a11f3ae29cf9b997463aa10fa61d89fdf2cf8a9df9485ebb9f81f9459e9587"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}